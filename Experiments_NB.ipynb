{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import DataPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\vscodeprojects\\Lime-Enhancements\\data_prep.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  compas_df['length_of_stay'] = (pd.to_datetime(compas_df['c_jail_out']) - pd.to_datetime(compas_df['c_jail_in'])).dt.days\n"
     ]
    }
   ],
   "source": [
    "data_location = \"./data/compas-scores-two-years.csv\"\n",
    "compas_score_full = pd.read_csv(data_location)\n",
    "data=DataPrep(compas_score_full)\n",
    "X,y,cols=data.get()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8307692307692308\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.42      0.47       224\n",
      "           1       0.88      0.92      0.90      1011\n",
      "\n",
      "    accuracy                           0.83      1235\n",
      "   macro avg       0.71      0.67      0.69      1235\n",
      "weighted avg       0.82      0.83      0.82      1235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_model = GaussianNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = naive_bayes_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 94 130]\n",
      " [ 79 932]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_std = scaler.fit_transform(std_per_variable.values.reshape(-1, 1))\n",
    "\n",
    "scaled_std_df = pd.DataFrame({'Feature': std_per_variable.index, 'Scaled Standard Deviation': scaled_std.flatten()})\n",
    "scaled_std_df = scaled_std_df.sort_values(by='Scaled Standard Deviation', ascending=False)\n",
    "\n",
    "print(\"Sorted Scaled Standard Deviation:\")\n",
    "print(scaled_std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled Information Gain:\n",
      "             Feature  Scaled Information Gain\n",
      "2       priors_count                 1.000000\n",
      "1     two_year_recid                 0.741626\n",
      "8               race                 0.431101\n",
      "0                age                 0.430770\n",
      "3     length_of_stay                 0.417032\n",
      "4  c_charge_degree_F                 0.217664\n",
      "5  c_charge_degree_M                 0.173355\n",
      "6         sex_Female                 0.086700\n",
      "7           sex_Male                 0.078037\n"
     ]
    }
   ],
   "source": [
    "information_gain = mutual_info_classif(X, y, discrete_features='auto', random_state=42)\n",
    "\n",
    "scaled_information_gain = information_gain / information_gain.max()\n",
    "\n",
    "information_gain_df = pd.DataFrame({'Feature': X.columns, 'Scaled Information Gain': scaled_information_gain})\n",
    "information_gain_df = information_gain_df.sort_values(by='Scaled Information Gain', ascending=False)\n",
    "\n",
    "print(\"\\nScaled Information Gain:\")\n",
    "print(information_gain_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing in LIME base "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if model_regressor is None:\n",
    "            model_regressor = GaussianNB(random_state=self.random_state)\n",
    "easy_model = model_regressor\n",
    "easy_model.fit(neighborhood_data[:, used_features],\n",
    "                       labels_column, sample_weight=weights)\n",
    "prediction_score = easy_model.score(\n",
    "            neighborhood_data[:, used_features],\n",
    "            labels_column, sample_weight=weights)\n",
    "\n",
    "local_pred = easy_model.predict(neighborhood_data[0, used_features].reshape(1, -1))\n",
    "information_gain = mutual_info_classif(X, y, discrete_features='auto', random_state=42)\n",
    "\n",
    "scaled_information_gain = information_gain / information_gain.max()\n",
    "\n",
    "information_gain_df = pd.DataFrame({'Feature': X.columns, 'Scaled Information Gain': scaled_information_gain})\n",
    "information_gain_df = information_gain_df.sort_values(by='Scaled Information Gain', ascending=False)\n",
    "\n",
    "easy_model_coef=information_gain_df\n",
    "if self.verbose:\n",
    "    print('Prediction_local', local_pred, )\n",
    "    print('Right:', neighborhood_labels[0, label])\n",
    "return (sorted(zip(used_features, easy_model_coef),\n",
    "                       key=lambda x: np.abs(x[1]), reverse=True),\n",
    "                prediction_score, local_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_builder import ModelBuild\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\pandas\\_libs\\index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m modelBuilder \u001b[38;5;241m=\u001b[39m ModelBuild(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecisionTree\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model, accuracy, cm \u001b[38;5;241m=\u001b[39m modelBuilder\u001b[38;5;241m.\u001b[39mtrain_eval(X_train, y_train, X_test, y_test)\n\u001b[1;32m----> 4\u001b[0m explainer_lime \u001b[38;5;241m=\u001b[39m modelBuilder\u001b[38;5;241m.\u001b[39mnaive_bayes_explain(X_train, X_cols)\n\u001b[0;32m      6\u001b[0m instance_no \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m76\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#instance to explain (for easy column viewing converted to pandas)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\vscodeprojects\\Lime-Enhancements\\model_builder.py:32\u001b[0m, in \u001b[0;36mModelBuild.naive_bayes_explain\u001b[1;34m(X_train, X_cols)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnaive_bayes_explain\u001b[39m(X_train, X_cols):\n\u001b[1;32m---> 32\u001b[0m     self_lime \u001b[38;5;241m=\u001b[39m LimeTabularExplainer_NB(training_data\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[0;32m     33\u001b[0m                         feature_names\u001b[38;5;241m=\u001b[39mX_cols,\n\u001b[0;32m     34\u001b[0m                         class_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgood\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     35\u001b[0m                         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m self_lime\n",
      "File \u001b[1;32mc:\\Users\\Asus\\vscodeprojects\\Lime-Enhancements\\NB_lime\\lime_tabular.py:219\u001b[0m, in \u001b[0;36mLimeTabularExplainer_NB.__init__\u001b[1;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[0;32m    212\u001b[0m     discretizer \u001b[38;5;241m=\u001b[39m StatsDiscretizer(\n\u001b[0;32m    213\u001b[0m         training_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_features,\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, labels\u001b[38;5;241m=\u001b[39mtraining_labels,\n\u001b[0;32m    215\u001b[0m         data_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_data_stats,\n\u001b[0;32m    216\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m discretizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquartile\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscretizer \u001b[38;5;241m=\u001b[39m QuartileDiscretizer(\n\u001b[0;32m    220\u001b[0m         training_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_features,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, labels\u001b[38;5;241m=\u001b[39mtraining_labels,\n\u001b[0;32m    222\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m discretizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecile\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscretizer \u001b[38;5;241m=\u001b[39m DecileDiscretizer(\n\u001b[0;32m    225\u001b[0m         training_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_features,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, labels\u001b[38;5;241m=\u001b[39mtraining_labels,\n\u001b[0;32m    227\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\lime\\discretize.py:178\u001b[0m, in \u001b[0;36mQuartileDiscretizer.__init__\u001b[1;34m(self, data, categorical_features, feature_names, labels, random_state)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, categorical_features, feature_names, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 178\u001b[0m     BaseDiscretizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, categorical_features,\n\u001b[0;32m    179\u001b[0m                              feature_names, labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m    180\u001b[0m                              random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\lime\\discretize.py:51\u001b[0m, in \u001b[0;36mBaseDiscretizer.__init__\u001b[1;34m(self, data, categorical_features, feature_names, labels, random_state, data_stats)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m check_random_state(random_state)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# To override when implementing a custom binning\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbins(data, labels)\n\u001b[0;32m     52\u001b[0m bins \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39munique(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m bins]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Read the stats from data_stats if exists\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\lime\\discretize.py:185\u001b[0m, in \u001b[0;36mQuartileDiscretizer.bins\u001b[1;34m(self, data, labels)\u001b[0m\n\u001b[0;32m    183\u001b[0m bins \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_discretize:\n\u001b[1;32m--> 185\u001b[0m     qts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39mpercentile(data[:, feature], [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m75\u001b[39m]))\n\u001b[0;32m    186\u001b[0m     bins\u001b[38;5;241m.\u001b[39mappend(qts)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bins\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3809\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m   3810\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5923\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5924\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5925\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "X_cols=X.columns\n",
    "modelBuilder = ModelBuild('DecisionTree')\n",
    "model, accuracy, cm = modelBuilder.train_eval(X_train, y_train, X_test, y_test)\n",
    "explainer_lime = modelBuilder.naive_bayes_explain(X_train, X_cols)\n",
    "\n",
    "instance_no = 76\n",
    "#instance to explain (for easy column viewing converted to pandas)\n",
    "print(f\"Instance to be explained:\\n{pd.DataFrame(X_test, columns=X_cols).iloc[instance_no]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 5)\n",
      "(5000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0.        , 0.33333333, 0.5       , 0.66666667, 1.        ]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m exp_inst \u001b[38;5;241m=\u001b[39m explainer_lime\u001b[38;5;241m.\u001b[39mexplain_instance(X_test[instance_no], model\u001b[38;5;241m.\u001b[39mpredict_proba, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Downloads\\Lime-Enhancements-main (1)\\Lime-Enhancements-main\\NB_lime\\lime_tabular.py:460\u001b[0m, in \u001b[0;36mLimeTabularExplainer_NB.explain_instance\u001b[1;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor, sampling_method)\u001b[0m\n\u001b[0;32m    455\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[0;32m    457\u001b[0m     (ret_exp\u001b[38;5;241m.\u001b[39mintercept[label],\n\u001b[0;32m    458\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_exp[label],\n\u001b[0;32m    459\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mscore[label],\n\u001b[1;32m--> 460\u001b[0m      ret_exp\u001b[38;5;241m.\u001b[39mlocal_pred[label]) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mexplain_instance_with_data(\n\u001b[0;32m    461\u001b[0m             scaled_data,\n\u001b[0;32m    462\u001b[0m             yss,\n\u001b[0;32m    463\u001b[0m             distances,\n\u001b[0;32m    464\u001b[0m             label,\n\u001b[0;32m    465\u001b[0m             num_features,\n\u001b[0;32m    466\u001b[0m             model_regressor\u001b[38;5;241m=\u001b[39mmodel_regressor,\n\u001b[0;32m    467\u001b[0m             feature_selection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection)\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    470\u001b[0m     ret_exp\u001b[38;5;241m.\u001b[39mintercept[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m ret_exp\u001b[38;5;241m.\u001b[39mintercept[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Asus\\Downloads\\Lime-Enhancements-main (1)\\Lime-Enhancements-main\\NB_lime\\lime_base.py:197\u001b[0m, in \u001b[0;36mLimeBase.explain_instance_with_data\u001b[1;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28mprint\u001b[39m(neighborhood_data[:, used_features]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels_column\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 197\u001b[0m easy_model\u001b[38;5;241m.\u001b[39mfit(neighborhood_data[:, used_features],\n\u001b[0;32m    198\u001b[0m                labels_column)\n\u001b[0;32m    199\u001b[0m prediction_score \u001b[38;5;241m=\u001b[39m easy_model\u001b[38;5;241m.\u001b[39mscore(\n\u001b[0;32m    200\u001b[0m     neighborhood_data[:, used_features],\n\u001b[0;32m    201\u001b[0m     labels_column, sample_weight\u001b[38;5;241m=\u001b[39mweights)\n\u001b[0;32m    203\u001b[0m local_pred \u001b[38;5;241m=\u001b[39m easy_model\u001b[38;5;241m.\u001b[39mpredict(neighborhood_data[\u001b[38;5;241m0\u001b[39m, used_features]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\sklearn\\naive_bayes.py:263\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_fit(\n\u001b[0;32m    264\u001b[0m     X, y, np\u001b[38;5;241m.\u001b[39munique(y), _refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight\n\u001b[0;32m    265\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\sklearn\\naive_bayes.py:422\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _refit:\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m first_call \u001b[38;5;241m=\u001b[39m _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n\u001b[0;32m    423\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39mfirst_call)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:422\u001b[0m, in \u001b[0;36m_check_partial_fit_first_call\u001b[1;34m(clf, classes)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`classes=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` is not the same as on last call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto partial_fit, was: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (classes, clf\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;66;03m# This is the first call to partial_fit\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m         clf\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m unique_labels(classes)\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# classes is None and clf.classes_ has already previously been set:\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;66;03m# nothing to do\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:105\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    103\u001b[0m _unique_labels \u001b[38;5;241m=\u001b[39m _FN_UNIQUE_LABELS\u001b[38;5;241m.\u001b[39mget(label_type, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _unique_labels:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(ys))\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_array_api_compliant:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([0.        , 0.33333333, 0.5       , 0.66666667, 1.        ]),)"
     ]
    }
   ],
   "source": [
    "exp_inst = explainer_lime.explain_instance(X_test[instance_no], model.predict_proba, num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
